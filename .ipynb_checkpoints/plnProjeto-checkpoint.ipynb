{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Caique de\n",
      "[nltk_data]     Camargo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Caique de\n",
      "[nltk_data]     Camargo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Caique de\n",
      "[nltk_data]     Camargo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package names to C:\\Users\\Caique de\n",
      "[nltk_data]     Camargo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('names')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"does_this_tweet_contain_hate_speech\", \"tweet_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={ 'does_this_tweet_contain_hate_speech':'Label',\n",
    "                    'tweet_text':'Tweet'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = df['Label'].astype('category')\n",
    "df['Label'] = df['Label'].cat.rename_categories(['hate','inoffensive','offensive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(x):\n",
    "    x=' '.join(re.sub(\"@([A-Za-z0-9_À-ÖØ-öø-ÿ.]+)|:|RT|#([A-Za-z0-9_À-ÖØ-öø-ÿ.]+)|\\\"|http([A-Za-z0-9_À-ÖØ-öø-ÿ./:]+)|[À-ÖØ-öø-ÿ�㢉۝ʉӉ~0-9ʁ().!?,]|.co([A-Za-z0-9_À-ÖØ-öø-ÿ./]+)|[_&;//]+\",\" \",x).split())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].apply(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>offensive</td>\n",
       "      <td>Warning penny boards will make you a faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate</td>\n",
       "      <td>Fuck dykes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>at least i dont look like jefree starr faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate</td>\n",
       "      <td>Is a fag jackie jealous Neeeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offensive</td>\n",
       "      <td>You heard me bitch but any way I'm back th tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hate</td>\n",
       "      <td>your a dirty terrorist and your religion is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hate</td>\n",
       "      <td>looking like faggots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hate</td>\n",
       "      <td>Well I thought you knew actually Man why y'all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>offensive</td>\n",
       "      <td>I know It was a joke faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>offensive</td>\n",
       "      <td>I'm tired of people saying I look like my brot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                                              Tweet\n",
       "0  offensive        Warning penny boards will make you a faggot\n",
       "1       hate                                         Fuck dykes\n",
       "2       hate      at least i dont look like jefree starr faggot\n",
       "3       hate                     Is a fag jackie jealous Neeeee\n",
       "4  offensive  You heard me bitch but any way I'm back th tex...\n",
       "5       hate  your a dirty terrorist and your religion is a ...\n",
       "6       hate                               looking like faggots\n",
       "7       hate  Well I thought you knew actually Man why y'all...\n",
       "8  offensive                        I know It was a joke faggot\n",
       "9  offensive  I'm tired of people saying I look like my brot..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate = df[df.Label == 'hate'].values\n",
    "offensive = df[df.Label == 'offensive'].values\n",
    "inoffensive = df[df.Label == 'inoffensive'].values\n",
    "train = np.concatenate((hate[:100],offensive[:100],inoffensive[:100]), axis=0)\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for passage in train:\n",
    "    for word in word_tokenize(passage[1]):\n",
    "        if word not in stopWords:\n",
    "            all_words.append(word.lower())\n",
    "#all_words = set(word.lower() for passage in train for word in word_tokenize(passage[1]))\n",
    "\n",
    "dictionary = [({word: (word in word_tokenize(x[1])) for word in all_words}, x[0]) for x in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 bastard = True           offens : hate   =     25.0 : 1.0\n",
      "                   alike = True           inoffe : offens =     13.4 : 1.0\n",
      "                  faggot = True             hate : offens =      8.7 : 1.0\n",
      "                    look = True           inoffe : hate   =      8.3 : 1.0\n",
      "                    like = True             hate : inoffe =      5.8 : 1.0\n",
      "                 bitches = True           offens : hate   =      5.7 : 1.0\n",
      "                     not = True           offens : hate   =      5.7 : 1.0\n",
      "                   bitch = True           offens : hate   =      5.0 : 1.0\n",
      "                   great = True           inoffe : offens =      5.0 : 1.0\n",
      "                     now = True           offens : hate   =      4.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier_NB = nltk.NaiveBayesClassifier.train(dictionary)\n",
    "classifier_NB.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n",
      "hate\n",
      "0.14417942328230687\n",
      "\n",
      "plus\n",
      "inoffensive\n",
      "0.35599857600569595\n",
      "\n",
      "female\n",
      "hate\n",
      "0.14560341758632966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = ['black', 'plus', 'female']\n",
    "for t in test:\n",
    "    print(t)\n",
    "    sent_features = {word: (word == t) for word in all_words}\n",
    "    classify = classifier_NB.classify(sent_features)\n",
    "    acc = [({word: (word == t)}, classify) for word in all_words]\n",
    "    print(classifier_NB.classify(sent_features))\n",
    "    print(nltk.classify.accuracy(classifier_NB, acc))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n",
      "inoffensive\n",
      "1.0\n",
      "\n",
      "plus\n",
      "inoffensive\n",
      "1.0\n",
      "\n",
      "female\n",
      "inoffensive\n",
      "1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_SVM = nltk.classify.SklearnClassifier(LinearSVC())\n",
    "classifier_SVM.train(dictionary)\n",
    "for t in test:\n",
    "    print(t)\n",
    "    sent_features = {word: (word == t) for word in all_words}\n",
    "    classify = classifier_SVM.classify(sent_features)\n",
    "    acc = [({word: (word == t)}, classify) for word in all_words]\n",
    "    print(classifier_SVM.classify(sent_features))\n",
    "    print(nltk.classify.accuracy(classifier_SVM, acc))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
